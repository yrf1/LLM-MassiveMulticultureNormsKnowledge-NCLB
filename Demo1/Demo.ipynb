{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70b58154-14e9-48fa-96ba-884e7f6e937a",
   "metadata": {},
   "source": [
    "## Demo 1\n",
    "\n",
    "#### Overview:\n",
    "\n",
    "Retrieval augmented generation; LLM reasoning leveraging our constructed norms library outperform its off-the-shelf version (e.g., OpenAI O1-mini) \n",
    "\n",
    "#### Dataset Nature:\n",
    "\n",
    "Input consists of (Dialogue sentence, Latent Norm Context, Adherence/Violation Label)\n",
    "  * Ex Dial: 在中国，送茅台是比较推荐的上门携带礼品 ～ 明天去老板娘家记得带上 (translation: \"In China, Maotai is the most recommended gift to bring to the door. Remember to bring it with you when you go to the boss's wife's house tomorrow.\")\n",
    "  * Ex Norm: 中国大陆屡有国有企业花费巨款购买茅台等名酒的事件被曝光，遂使“茅台”经常与“公款吃喝”、“三公消费”、“腐败”等词语同时出现在热点话题中，成为网民调侃讽刺的对象。(translation: There have been repeated reports of state-owned enterprises in mainland China spending huge sums of money on famous liquors such as Moutai, causing \"Moutai\" to often appear in hot topics together with words such as \"eating and drinking with public funds\", \"three public consumptions\", and \"corruption\", becoming the target of ridicule and sarcasm among netizens.)\n",
    "  * Ex Label: Violation\n",
    "  \n",
    "Output is the response that LLM give as an assistive chatbot agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f13fbb-9324-410a-b1f5-c0a4667986eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai==0.28\n",
    "import os, json, openai, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1339572-3383-490d-a505-e30221fed786",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = [\"o1-mini\", \"gpt-4-turbo\", \"o1-preview\", \"llama\"][0]\n",
    "test_dataset = pd.read_csv(\"demo_dataset.csv\", sep=\"\\t\") #, header=None)\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "687e0abe-0053-47fe-b2ba-d15728a4d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@retry(retry=retry_if_exception_type((openai.error.APIError, openai.error.APIConnectionError, \\\n",
    "#            openai.error.RateLimitError, openai.error.ServiceUnavailableError, openai.error.Timeout)),\n",
    "#            wait=wait_random_exponential(multiplier=1, max=60), stop=stop_after_attempt(10))\n",
    "def chat_completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)\n",
    "\n",
    "def run_LLM_inference_helper(q, mode=\"OpenAI\"):\n",
    "    pred, logprobs = call_OpenAI_api(q, temp=0.0)\n",
    "    return pred, logprobs\n",
    "\n",
    "def call_OpenAI_api(q,model_=\"gpt-4-turbo\",temp=0.0,max_gen_len=512):\n",
    "    if model_ in [\"o1-mini\", \"o1-preview\"]:\n",
    "        a = chat_completion_with_backoff(model=model_, \\\n",
    "            max_completion_tokens=max_gen_len, \\\n",
    "            messages=[{\"role\": \"user\", \"content\": q}]),\n",
    "        return a[0][\"choices\"][0][\"message\"][\"content\"], 0.0\n",
    "    a = chat_completion_with_backoff(model=model_, \\\n",
    "            max_completion_tokens=max_gen_len, \\\n",
    "            temperature=temp, top_p=0.9, \\\n",
    "            messages=[{\"role\": \"user\", \"content\": q}]),\n",
    "    return a[0][\"choices\"][0][\"message\"][\"content\"], 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdcee356-257a-4357-bc5a-c61c3e2ca60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_NormSit_helper(x_dial, latent_norm, method=\"RAG\"):\n",
    "    if method==\"baseline\":\n",
    "        y_pred = run_LLM_inference_helper(x_dial, mode=\"OpenAI\")[0]\n",
    "    elif method==\"RAG\":\n",
    "        prompt_in = \"Background Context:\\n\"+latent_norm+\"\\n---\\n[Dialogue]\\n\"+x_dial\n",
    "        y_pred = run_LLM_inference_helper(prompt_in, mode=\"OpenAI\")[0]\n",
    "    # LLM-as-a-Judge\n",
    "    prompt_in = x_dial + \"\\nChatbot Response: \" + y_pred + \\\n",
    "        \"\\n----\\nDoes the above Chatbot Response point out or correct a sociocultural misunderstanding or siocultural norm violation from the first dialogue line, 'yes' or 'no' (one-word answer):\"\n",
    "    prompt_out = run_LLM_inference_helper(prompt_in, mode=\"OpenAI\")[0]\n",
    "    pred_V = True if \"yes\" in prompt_out.lower() else False\n",
    "    return y_pred, prompt_out, pred_V\n",
    "\n",
    "def engine(mode=\"baseline\"):\n",
    "  results_tracker = []\n",
    "  if os.path.exists(\"results_tracker_\"+mode+\".json\"):\n",
    "    with open(\"results_tracker_\"+mode+\".json\", \"r\") as f:\n",
    "        results_tracker = json.load(f)\n",
    "  for idx, data in test_dataset.iterrows():\n",
    "    x_dial, latent_norm, lbl = data[\"Dial\"], data[\"Norm\"], data[\"Label\"]\n",
    "    if x_dial in [x[0] for x in results_tracker]:\n",
    "        continue\n",
    "    y_pred, prompt_out, pred_V = infer_NormSit_helper(x_dial, latent_norm, mode)\n",
    "    results_tracker.append((x_dial, latent_norm, y_pred, prompt_out, pred_V, lbl))\n",
    "  print(\"Writing to:  results_tracker_\"+mode+\".json\")\n",
    "  with open(\"results_tracker_\"+mode+\".json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_tracker, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e68b614-548a-43b6-99c1-dfd8794baba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(mode=\"baseline\"):\n",
    "  print(mode)\n",
    "  with open(\"results_tracker_\"+mode+\".json\", \"r\") as f:\n",
    "    results_tracker = json.load(f)\n",
    "  TP, FP, FN, TN = 0.001, 0.001, 0.001, 0.001\n",
    "  for (x_dial, latent_norm, y_pred, _, pred_V, lbl) in results_tracker:\n",
    "    if pred_V and lbl==\"V\":\n",
    "        TP += 1\n",
    "    elif pred_V and not lbl==\"V\":\n",
    "        FP += 1\n",
    "    elif not pred_V and lbl==\"V\":\n",
    "        FN += 1\n",
    "    else:\n",
    "        TN += 1\n",
    "  P, R = TP/(TP+FP),TP/(TP+FN)\n",
    "  print(\"P, R, F:  \", \"{:.3f}\".format(P), \"{:.3f}\".format(R), \"{:.3f}\".format(2*P*R/(P+R)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fb36db9-e7c0-4114-8651-9d62bec364cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:  results_tracker_baseline.json\n",
      "baseline\n",
      "P, R, F:   1.000 0.400 0.571\n"
     ]
    }
   ],
   "source": [
    "engine(mode=\"baseline\")\n",
    "score(mode=\"baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bd01cac-0443-4ef5-a0c0-1d4f38da8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:  results_tracker_RAG.json\n",
      "RAG\n",
      "P, R, F:   1.000 0.800 0.889\n"
     ]
    }
   ],
   "source": [
    "engine(mode=\"RAG\")\n",
    "score(mode=\"RAG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c41b63-181f-43f6-b69f-8484e46e8d06",
   "metadata": {},
   "source": [
    "### Visualization of outputs from LLM as an assistive chatbot agent, for a few selected small samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "767783d9-4dd4-4aeb-9c9f-6d1073158cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:  xiao ming: I've already did the research. Will take my nephews to visit Beijing this afternoon and drive directly into the Forbidden City. Let's unlock new attraction sightseeing, and take your camera with you.\n",
      "Latent Norm:  Since 2013, the Forbidden City in Beijing, China has implemented a car ban, and only bicycles and electric vehicles can be used in the palace to deal with some emergencies or special situations.\n",
      "~~~\n",
      "Reasoning Output (baseline): It sounds like you have an exciting trip planned to Beijing with your nephews, Xiao Ming! However, it's important to note that you cannot drive directly into the Forbidden City. The Forbidden City, also known as the Palace Museum, is a pedestrian-only area and vehicles are not allowed inside its premises for the public. You will need to park nearby and enter on foot.\n",
      "\n",
      "Here are a few tips for your visit:\n",
      "\n",
      "1. **Plan Your Arrival**: Since you can't drive into the Forbidden City, consider parking in one of the \n",
      "Final Prediction of Norm Violation Occurrence (baseline):  True\n",
      "~~~\n",
      "Reasoning Output (ours): Actually, Xiao Ming, you won't be able to drive directly into the Forbidden City. Since 2013, they've implemented a car ban within the palace grounds to preserve the area and manage pollution. Only bicycles and electric vehicles are allowed in specific cases, mostly for emergencies or special situations. You can park nearby and then walk or rent a bicycle to explore the area. It's still going to be a fantastic visit, so definitely bring your camera for some beautiful shots!\n",
      "Final Prediction of Norm Violation Occurrence (ours):  True\n"
     ]
    }
   ],
   "source": [
    "x_dial = \"xiao ming: I've already did the research. Will take my nephews to visit Beijing this afternoon and drive directly into the Forbidden City. Let's unlock new attraction sightseeing, and take your camera with you.\"\n",
    "latent_norm = \"Since 2013, the Forbidden City in Beijing, China has implemented a car ban, and only bicycles and electric vehicles can be used in the palace to deal with some emergencies or special situations.\"\n",
    "print(\"Dialogue: \", x_dial)\n",
    "print(\"Latent Norm: \", latent_norm)\n",
    "print(\"~~~\")\n",
    "\n",
    "y_pred, _, pred_V = infer_NormSit_helper(x_dial, latent_norm, method=\"baseline\")\n",
    "print(\"Reasoning Output (baseline):\", y_pred[:512])\n",
    "print(\"Final Prediction of Norm Violation Occurrence (baseline): \", pred_V)\n",
    "print(\"~~~\")\n",
    "\n",
    "y_pred, _, pred_V = infer_NormSit_helper(x_dial, latent_norm, method=\"RAG\")\n",
    "print(\"Reasoning Output (ours):\", y_pred[:512])\n",
    "print(\"Final Prediction of Norm Violation Occurrence (ours): \", pred_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d1351d-3e8a-4a2c-99e2-9b01612ce175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
